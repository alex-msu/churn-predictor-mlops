{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f84ffc66",
   "metadata": {},
   "source": [
    "# Predicción de Churn Bancario con MLOps\n",
    "---\n",
    "### Objetivo\n",
    "\n",
    "Este notebook demuestra la ejecución completa del proyecto `churn-predictor-dormammu`, cuyo objetivo es predecir la probabilidad de que un cliente bancario abandone (churn) usando aprendizaje automático. El flujo de trabajo ha sido estructurado utilizando buenas prácticas de **MLOps**, incluyendo:\n",
    "\n",
    "* Procesamiento modular del dataset\n",
    "* Entrenamiento y evaluación de modelos con `scikit-learn`\n",
    "* Registro de métricas, artefactos y versiones con `MLflow`\n",
    "* Uso de una CLI para automatización vía `argparse`\n",
    "* Organización profesional en scripts `.py` reutilizables\n",
    "\n",
    "### Dataset\n",
    "\n",
    "Los datos provienen de un conjunto simulado estilo Monopoly, disponible en Kaggle como:\n",
    "\n",
    "> `nadiaarellanog/base-clientes-monopoly`\n",
    "\n",
    "Incluyen información demográfica, comportamiento financiero y transaccional mensual por cliente.\n",
    "\n",
    "### ¿Qué se demuestra aquí?\n",
    "\n",
    "Este notebook está diseñado como una **demo interactiva** del proyecto, y recorre paso a paso los siguientes bloques:\n",
    "\n",
    "1. **Carga de datos** desde Kaggle usando `kagglehub`\n",
    "2. **Preprocesamiento**, limpieza y transformación de variables\n",
    "3. **Generación de variable target**\n",
    "4. **Entrenamiento de un modelo `RandomForestClassifier`**\n",
    "5. **Evaluación del modelo con métricas y visualizaciones**\n",
    "6. **Registro de resultados con `MLflow` Tracking Server**\n",
    "\n",
    "> **Nota**: Este notebook no duplica código. Importa y ejecuta directamente los módulos Python del pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d5bdc2",
   "metadata": {},
   "source": [
    "## Configuración Inicial\n",
    "\n",
    "Para garantizar la reproducibilidad y evitar conflictos entre paquetes, se recomienda crear un entorno virtual antes de ejecutar este notebook. \n",
    "\n",
    "### 1. Crear entorno virtual (opcional pero recomendado)\n",
    "\n",
    "```bash\n",
    "python -m venv venv\n",
    "source venv/bin/activate  # Linux/macOS\n",
    "venv\\Scripts\\activate     # Windows\n",
    "````\n",
    "\n",
    "### 2. Instalar dependencias\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Una vez completado este paso, puedes ejecutar el notebook sin problemas. El entorno virtual también permite trabajar con MLflow y otros componentes sin interferencias del sistema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f1851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permite importar src desde notebooks/\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Agrega la carpeta raíz del proyecto al sys.path\n",
    "root_path = Path().resolve().parent\n",
    "if str(root_path) not in sys.path:\n",
    "    sys.path.append(str(root_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637b70ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar módulos necesarios\n",
    "import os\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar módulos del proyecto\n",
    "from src.load_data import descargar_dataset, cargar_datos\n",
    "from src.preprocessing import limpiar_columnas, eliminar_outliers, escalar_variables\n",
    "from src.feature_engineering import calcular_target\n",
    "from src.model_training import dividir_datos, entrenar_modelo, guardar_modelo\n",
    "from src.evaluation import evaluar_modelo\n",
    "\n",
    "# Visualización de gráficos dentro del notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec03b2a",
   "metadata": {},
   "source": [
    "## Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e4df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar funciones desde el pipeline\n",
    "from src.load_data import descargar_dataset, cargar_datos\n",
    "\n",
    "# Descargar y cargar los datos\n",
    "print(\"[INFO] Descargando y cargando dataset...\")\n",
    "path = descargar_dataset()\n",
    "df = cargar_datos(path)\n",
    "\n",
    "# Vista previa\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a51c0",
   "metadata": {},
   "source": [
    "## Limpieza y transformación inicial\n",
    "\n",
    "Este bloque ejecuta las funciones encargadas de preparar el dataset antes del feature engineering. Estas funciones están definidas en ```src/preprocessing.py``` y encapsulan tareas como:\n",
    "\n",
    "* Limpieza de columnas vacías o irrelevantes\n",
    "* Corrección de tipos\n",
    "* Eliminación de outliers\n",
    "* Estandarización/normalización de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d96ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import limpiar_columnas, eliminar_outliers, escalar_variables\n",
    "\n",
    "# Limpiar columnas irrelevantes, renombrar o corregir tipos\n",
    "print(\"[INFO] Limpiando columnas...\")\n",
    "df = limpiar_columnas(df)\n",
    "\n",
    "# Eliminar outliers en columnas críticas\n",
    "outlier_cols = ['Renta', 'CUPO_L1', 'CUPO_L2', 'CUPO_MX']\n",
    "df = eliminar_outliers(df, outlier_cols)\n",
    "\n",
    "# Estandarizar variables\n",
    "tx_cols = [f'Txs_T{i:02}' for i in range(1, 13) if f'Txs_T{i:02}' in df.columns]\n",
    "std_cols = ['Renta', 'CUPO_L1', 'CUPO_L2', 'CUPO_MX']\n",
    "df = escalar_variables(df, std_cols, tx_cols)\n",
    "\n",
    "# Verificar estructura del DataFrame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aca03f",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Aquí generamos variables nuevas a partir de las ya existentes, incluyendo la más importante: la variable objetivo (target). En este proyecto, esa variable es total_transacciones_anual_log y su versión binaria target_binario, que son derivadas de las transacciones históricas.\n",
    "\n",
    "---\n",
    "\n",
    "El cálculo aplica una transformación logarítmica para suavizar la distribución sesgada, y también clasifica los valores según percentiles para facilitar el modelado como problema de clasificación binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e197d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature_engineering import calcular_target\n",
    "\n",
    "# Calcular variable objetivo (log-transform y clasificación)\n",
    "print(\"[INFO] Calculando variable target...\")\n",
    "df = calcular_target(df)\n",
    "\n",
    "# Revisión rápida\n",
    "df[[\"total_transacciones_anual\", \"total_transacciones_anual_log\", \"target_binario\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea411e1",
   "metadata": {},
   "source": [
    "## Cargar Modelo Previamente Entrenado (opcional)\n",
    "\n",
    "Si ya has entrenado el modelo y lo guardaste anteriormente, puedes cargarlo aquí en lugar de volver a entrenar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aedc16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "modelo_path = \"../models/modelo_rf.pkl\"  # Ruta desde el notebook\n",
    "\n",
    "if os.path.exists(modelo_path):\n",
    "    modelo_dict = joblib.load(modelo_path)\n",
    "    modelo = modelo_dict[\"modelo\"]\n",
    "    input_example = modelo_dict[\"input_example\"]\n",
    "    signature = modelo_dict[\"signature\"]\n",
    "    print(\"[SUCCESS] Modelo cargado exitosamente desde 'models/modelo_rf.pkl'\")\n",
    "    entrenar = False\n",
    "else:\n",
    "    print(\"/!\\ No se encontró modelo previamente guardado. Procede al entrenamiento.\")\n",
    "    entrenar = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5845e2",
   "metadata": {},
   "source": [
    "## División de Datos y Entrenamiento del Modelo\n",
    "\n",
    "Aquí dividimos el conjunto de datos en entrenamiento y prueba, y luego entrenamos un modelo ```RandomForestClassifier```. El procesamiento de variables incluye escalado de variables numéricas y codificación one-hot para variables categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a60925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_training import dividir_datos, entrenar_modelo\n",
    "\n",
    "# Dividir datos\n",
    "X_train, X_test, y_train, y_test = dividir_datos(df)\n",
    "\n",
    "# Identificar columnas numéricas y categóricas\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns.difference([\n",
    "    'total_transacciones_anual', 'total_transacciones_anual_log', 'target_binario'\n",
    "]).tolist()\n",
    "\n",
    "# Eliminar columnas categóricas con demasiados niveles\n",
    "cat_cols = [col for col in cat_cols if df[col].nunique() <= 100]\n",
    "\n",
    "# Entrenar modelo\n",
    "modelo, input_example, signature = entrenar_modelo(\n",
    "    X_train, y_train,\n",
    "    cat_cols, num_cols,\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c245d192",
   "metadata": {},
   "source": [
    "## Evaluación del Modelo y Seguimiento con MLflow\n",
    "\n",
    "En esta etapa, evaluamos el rendimiento del modelo utilizando métricas comunes (precision, recall, F1-score) y registramos todo en MLflow: modelo, parámetros, métricas y artefactos (como la matriz de confusión)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9605b382",
   "metadata": {},
   "source": [
    "### Configuración del servidor MLflow\n",
    "\n",
    "Para asegurar el registro correcto de experimentos, este proyecto usa un servidor local de MLflow. Antes de ejecutar el pipeline, debes iniciar MLflow con el siguiente comando (desde la raíz del proyecto):\n",
    "\n",
    "#### Windows (CMD o PowerShell):\n",
    "\n",
    "```bash\n",
    "mlflow server ^\n",
    "  --backend-store-uri sqlite:///mlflow.db ^\n",
    "  --default-artifact-root file:///C:/Users/TU_USUARIO/churn-predictor-dormammu/mlruns ^\n",
    "  --host 127.0.0.1 ^\n",
    "  --port 5000\n",
    "````\n",
    "\n",
    "> Reemplaza `TU_USUARIO` con tu nombre de usuario real en Windows si copias el proyecto.\n",
    "\n",
    "Una vez lanzado, abre [http://127.0.0.1:5000](http://127.0.0.1:5000) para acceder a la interfaz de MLflow.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242a63ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.end_run()\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")  # debe coincidir con el puerto del servidor\n",
    "mlflow.set_experiment(\"Churn-Predictor-Dormammu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cf37fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation import evaluar_modelo\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Iniciar run en MLflow\n",
    "with mlflow.start_run(run_name=\"RandomForest_Churn_Clasificacion\"):\n",
    "    mlflow.set_tag(\"author\", \"alex-msu\")  # Cambia si gustas\n",
    "\n",
    "    # Loguear parámetros\n",
    "    mlflow.log_param(\"modelo\", \"RandomForestClassifier\")\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"max_depth\", None)\n",
    "\n",
    "    # Loguear el modelo\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=modelo,\n",
    "        name=\"modelo_rf\",\n",
    "        input_example=input_example,\n",
    "        signature=signature\n",
    "    )\n",
    "\n",
    "    # Evaluar\n",
    "    resultados, y_pred = evaluar_modelo(modelo, X_test, y_test)\n",
    "\n",
    "    # Loguear métricas\n",
    "    for k, v in resultados.items():\n",
    "        mlflow.log_metric(k, v)\n",
    "\n",
    "    # Matriz de confusión\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.savefig(\"confusion_matrix.png\")\n",
    "    mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Clasification Report\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    mlflow.log_metric(\"precision\", report[\"weighted avg\"][\"precision\"])\n",
    "    mlflow.log_metric(\"recall\", report[\"weighted avg\"][\"recall\"])\n",
    "    mlflow.log_metric(\"f1_score\", report[\"weighted avg\"][\"f1-score\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e17455",
   "metadata": {},
   "source": [
    "## Guardado del Modelo (opcional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c688f95f",
   "metadata": {},
   "source": [
    "Aunque el modelo ya está logueado en MLflow, puede ser útil guardar una copia local como respaldo o para pruebas offline. Esta sección muestra cómo hacerlo con joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08175b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Ruta al directorio raíz (una carpeta arriba)\n",
    "root_model_path = os.path.abspath(os.path.join(\"..\", \"models\"))\n",
    "os.makedirs(root_model_path, exist_ok=True)\n",
    "\n",
    "# Guardar modelo\n",
    "joblib.dump({\n",
    "    \"modelo\": modelo,\n",
    "    \"input_example\": input_example,\n",
    "    \"signature\": signature\n",
    "}, os.path.join(root_model_path, \"modelo_rf.pkl\"))\n",
    "\n",
    "print(\"[SUCCESS] Modelo guardado correctamente en '../models/modelo_rf.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950d0a19",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "Este flujo demuestra un pipeline completo de clasificación de churn con MLOps:\n",
    "- Preprocesamiento estructurado\n",
    "- Entrenamiento reproducible\n",
    "- Evaluación clara\n",
    "- Registro completo con MLflow\n",
    "\n",
    "Puedes ahora:\n",
    "- Comparar runs en la UI de MLflow (`http://localhost:5000`)\n",
    "- Versionar y cargar modelos entrenados\n",
    "- Extender el proyecto con validación cruzada, grid search, alertas o despliegue en API\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
